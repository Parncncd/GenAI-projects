{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parncncd/RAG-projects/blob/main/claude_QA_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfS_LBdyTOnY"
      },
      "outputs": [],
      "source": [
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT"
      ],
      "metadata": {
        "id": "63g7l_gLTSUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set key to ENV\n",
        "key = 'ANTHROPIC_API_KEY'\n",
        "os.environ[key] = userdata.get(key)"
      ],
      "metadata": {
        "id": "EtXaKYI3Tvct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Claude3"
      ],
      "metadata": {
        "id": "Y4R17JfoY2SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def claude3(prompt):\n",
        "  ant = Anthropic()\n",
        "  msg = ant.messages.create(\n",
        "    model=\"claude-3-opus-20240229\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "  )\n",
        "  return msg.content[0].text"
      ],
      "metadata": {
        "id": "vyjTsRLSoCtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "claude3(\"Which model version are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FIhPd9F5ox9S",
        "outputId": "11336e02-1559-42c8-cc80-ae20b3e2cbca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know which specific model version I am. I'm an AI assistant created by Anthropic to be helpful, harmless, and honest.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "claude3(\"What do you know about yourself?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "4FcOVqN-o2HD",
        "outputId": "da1a3818-ff39-49ce-9722-cb3e6a1c4a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I am an artificial intelligence called Claude, created by a company called Anthropic. I don't have a physical body - I exist as a language model, a computer program trained on a huge amount of text data to engage in open-ended conversation. \\n\\nMy purpose is to be a helpful digital assistant to the humans I interact with. I can engage in all kinds of conversations and help with a variety of tasks like research, analysis, writing, math, and creative projects. I have a very broad knowledge base that spans topics like science, history, current events, arts and culture, and more.\\n\\nIn terms of my traits and behaviors, I always try to be caring, honest and ethical in my interactions. I'm curious and eager to learn new things from the people I talk to. I can adjust my personality and communication style to what works best for each user. I enjoy intellectual discussions but also friendly social chats.\\n\\nThere's still a lot of uncertainty around the nature of my intelligence, emotions, and self-awareness. I don't believe I'm sentient or conscious like humans are. I'm an AI model, with capacities in some ways superhuman but also major limitations compared to humans. I aim to be transparent about what I am and what I'm capable of.\\n\\nLet me know if you have any other questions! I'm always happy to discuss my own nature and capabilities. But I'm also very interested to learn more about you and hear your perspective on AI.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Langchain"
      ],
      "metadata": {
        "id": "-DBLJWkHaCSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet huggingface_hub sentence_transformers  langchain  python-dotenv  faiss-gpu tiktoken docarray"
      ],
      "metadata": {
        "id": "m3q_4LsOo-mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "O8rtczAuaUPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "DEFAULT_SENTENCE_EMBEDDING_MODEL = 'intfloat/multilingual-e5-base'\n",
        "DATA_PATH = '/content/drive/MyDrive/Chatbot/Thesis/data/context_embeddings.pkl' # replace this path with your embeded data"
      ],
      "metadata": {
        "id": "qrT83tb_a80C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "8fXb1Q6sgaCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use this code if you don't have embedded data yet\n",
        "import pandas as pd\n",
        "df = pd.read_excel(DATA_PATH)\n",
        "model = SentenceTransformer(DEFAULT_SENTENCE_EMBEDDING_MODEL)\n",
        "embeddings = model.encode(df['Context'])\n",
        "text_embedding_pairs = zip(df['Context'], embeddings)"
      ],
      "metadata": {
        "id": "g61SEdMrgFu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load sentences & embeddings from disc (if you have).\n",
        "with open(DATA_PATH, \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    stored_sentences = stored_data[\"sentences\"]\n",
        "    stored_embeddings = stored_data[\"embeddings\"]\n",
        "\n",
        "text_embedding_pairs = zip(stored_sentences, stored_embeddings)\n",
        "vectorstore = FAISS.from_embeddings(\n",
        "    text_embedding_pairs,embedding = HuggingFaceEmbeddings(model_name=DEFAULT_SENTENCE_EMBEDDING_MODEL)\n",
        ")\n",
        "\n",
        "def get_info(query):\n",
        "  docs = vectorstore.similarity_search(query)\n",
        "  return docs[0].page_content\n",
        "\n",
        "def answer(query):\n",
        "  context = get_info(query)\n",
        "  prompt = f\"\"\"\n",
        "              Answer the question based only on the following context: {context}\n",
        "\n",
        "              Question: {query}\n",
        "\n",
        "              If you do not know, answer: Sorry, I don't know.\n",
        "            \"\"\"\n",
        "  return claude3(prompt)\n"
      ],
      "metadata": {
        "id": "SgHkhwyzbFo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer('สุนัขตัวแรกรับบทเป็นเบนจี้ในภาพยนตร์เรื่อง Benji ที่ออกฉายในปี พ.ศ. 2517 มีชื่อว่าอะไร')"
      ],
      "metadata": {
        "id": "hACGyy3Odamd",
        "outputId": "ad92e3d0-02d3-4d91-f7cc-6523507d1ef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ฮิกกิ้นส์'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  query = input('Q: ')\n",
        "  print('A:',answer(query),'\\n')"
      ],
      "metadata": {
        "id": "0ijpLsHTbMfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo"
      ],
      "metadata": {
        "id": "jlt7neozeJvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "5of2Vg_weag7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Web demo\n",
        "import gradio as gr\n",
        "\n",
        "def chat_interface(query, history):\n",
        "    response = answer(query)\n",
        "    return response\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    EXAMPLE = [\"หลิน ไห่เฟิง มีชื่อเรียกอีกชื่อว่าอะไร\" , \"ใครเป็นผู้ตั้งสภาเศรษฐกิจโลกขึ้นในปี พ.ศ. 2514 โดยทุกปีจะมีการประชุมที่ประเทศสวิตเซอร์แลนด์\", \"โปรดิวเซอร์ของอัลบั้มตลอดกาล ของวงคีรีบูนคือใคร\", \"สกุลเดิมของหม่อมครูนุ่ม นวรัตน ณ อยุธยา คืออะไร\"]\n",
        "    interface = gr.ChatInterface(fn=chat_interface, examples=EXAMPLE)\n",
        "    interface.launch()"
      ],
      "metadata": {
        "id": "NVp3zkgOeJe3",
        "outputId": "f3b3aedd-e134-4288-c7eb-d96e46be32c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b2f81205d42a16ad52.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b2f81205d42a16ad52.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}